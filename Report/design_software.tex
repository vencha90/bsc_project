\subsection{Software Design Considerations}

\todo{remove notes}
(10, 2100 w)

Has the student clearly described the design of their system? Is it described
in sufficient detail to make it easy for someone else to replicate the system?

Has the student justified the design decisions, and discussed alternatives that
were considered?

\todo{Move algorithm to implementation??}

\subsubsection{Road Network}
\label{sec:design:network}
\todo{move to implementation, this is too in-depth for arch}

A real world road network is represented as a weighted connected graph
constructed of edges (roads) and vertices (origins/destinations). Each vertex
has associated properties: a list of connected edges with their lengths
(weights), a passenger and a taxi (if present). Taxis can travel between
connected vertices, and are assumed to take the shortest routes and travel at a
constant speed. Passengers appear at nodes and when taxi is at a node  they can
interact.

Road networks have a specific structure that is different from generic randomly
generated graphs. \textcite{Eisenstat2011graphs+quadtree} believes that the
structure of the graphs is important for optimisation problems, giving the
example of optimising logistics operations for a fleet of vehicles where
algorithmic performance greatly differs from that on generic graphs. Uniform
planar graphs are a reasonably realistic way to represent road networks
\parencite{Eisenstat2011graphs+quadtree, Masucci2009graphs+london}. A way to
generate random planar graphs is suggested by
\textcite{Brinkmann2007graphs+generate}, including software called
\textit{plantri}.

Shortest paths in graphs can be calculated by Djikstra's algorithm
\parencite{Cormen2009algorithms}. However, calculating all possible shortest
paths is not necessary as some routes could never be travelled. Furthermore,
that may be unfeasible in a very large network as the number of paths grows
exponentially. Online calculation of a shortest path between two nodes in a
graph can be efficiently done using \textit{A-star} algorithm by
\textcite{Hart1968paths}.

\todo{graph library choice}


\subsubsection{Q-Learner}
\label{sec:design:ai}
\todo{move to implementation, this is too in-depth for arch}

State is based on the origin, passenger and intended destination. Actions a
taxi can take is enquiring a passenger for destination, offering a price or
driving to another place. If the passenger accepts the price, taxi drives the
passenger to the destination and receives a reward. Keeping track of the exact
passenger is not important. Each time step has a negative reward based on what
action the taxi is taking, always depending on time but also could depend on
distance travelled. The probability of the passenger accepting the fare is the
transition probability. This specifies the research problem as a finite MDP
according to the definition in Section \ref{sec:literature:ai:mdp} (although it
can be argued that prices could theoretically be a continuous space, in reality
they are not).

As described in section \ref{sec:requirements:ai}, Q-Learner is a simple and
adequate reinforcement learning method fit for the project. Of course, the very
basic Q-Learner will need to be extended to accomodate exploration in this
paricular case of having an active agent (see Section
\ref{sec:literature:ai:exploration}. Therefore an exploration constant
\(\varepsilon\) needs to be used for action selection, and it can stay fixed as
the horizon for the simulation will normally be unknown.

A further addition required for the Q-Learner is a step-size function. This
function is used to adjust for the bias of previous estimates. As a state is
being visited more and more, any new experiences are less and less important
compared to the old experiences, therefore the TD weights should be adjusted
less. This issue was discussed in more detail by
\textcite{Sutton1994ai+stepsize}, where three different algorithms are
introduced for optimising the step sizes for improved reinforcement learning
performance. Nevertheless, the policy will still converge even if the step size
simply decays (i.e \(\lim_{n \to \inf}\alpha(n) = 0\) where \(n\) is the number
of times a state has been visited). Therefore for simplicity the function can
be fixed as \(\alpha(n)=\frac{1}{n}\).

When the step size function is added to a basic Q-Learner, the algorithm
adapted from \textcite{Sutton1998ai+reinforcement} can be used as shown in
Algorithm \ref{algorithm:q}. This algorithm updates action-state pair value
estimates, and the learner can then select the optimal action depending on the
exploration function (not shown here).

\begin{algorithm}
  \caption{
  Q-learning. Algorithm that needs to be called after each transition. 
  Adapted from \textcite{Sutton1998ai+reinforcement}. 
  \label{algorithm:q}}

  \begin{algorithmic}[1]
    \Require 
      \Statex $s$ is the last state,
      \Statex $s'$ is the next state,
      \Statex $a$ is the last action,
      \Statex $A(s)$ is a set of actions for a state,
      \Statex $R$ is the immediate reward received,
      \Statex $Q$ is an array hosting the current action-value estimate
      \Statex $H$ is the visit history of state-action pairs,
      \Statex $\alpha$ is a step-size function,
      \Statex $\gamma$ is a discount factor.

      \Statex Policy $Q(s, a)$ is initialised arbitrarily
      \Statex History $H$ is empty

    \Function{Q\_learning}{$s,a,R,a'$}
      \State $\delta \gets R + 
              \gamma \cdot max_{a' \in A(s')} Q(s', a') - Q(s, a)$
      \State $Q(s, a) \gets Q(s, a) + \alpha \cdot \delta$
      \State $H(s, a) \gets H(s, a) + 1$
      \Return $Q, H$      
    \EndFunction
  \end{algorithmic}

\end{algorithm}

\subsection{Architecture} 
\label{sec:design:architecture}

\todo{consider implementation}

\begin{figure}
  \begin{center}
    \includegraphics[width=\textwidth]{../figures/software_overview}
    \caption{
      Software overview diagram
      \label{figure:design:software}
    }
  \end{center}
\end{figure}

A software overview diagram is shown in Figure \ref{figure:design:software}.
This section explains the diagram and how the software operates.

When running the simulation, initially some user inputs are processed by the
input module. It validates that the input data (initially parsed from files or
command line parameters) is correct, stopping the program and warning the user
if any invalid data was found. The rest of the system is then initialised
according to the parameters, and a simulation is started.

The environment module is the highest hierarchy simulation object where all
other objects operate in. It is used for keeping track of global variables such
as time and the road network. The environment can directly affect the taxi and
passengers, setting their parameters, and taxis can query the environment for
some information.

The road network is internally represented as a graph, and is where taxis and
passengers are located and interact in.

Passengers (passive agents) can accept or decline taxis' offers respective to
their internal state. If accepted, passengers travel with the taxi in the road
network and pay the agreed fare. Irregardless of the action taken, passengers
disappear after any action is completed.

Taxi (an active agent) is the most complex object in the software. Over time
taxi experiences its own costs (fixed costs and variable costs). Taxis can take
three types of actions: wait at a location, drive to a different location, or
offer a fare to a passenger (if one is present). Taxi's actions are decided by
its learner module. The taxi passes information from the environment to the
learner and receives calls to action. For example, the learner needs to know
what prices it can set (from taxi itself or the environment), what locations it
can drive to (from the road network), whether there is a passenger at the
current location (from the environment), what the passenger's answer to the
offer was (from the passenger).

Finally, there is an output module that logs simulation data to files for
analysis.


\subsection{Technologies}

One of the core technologies used was \textit{git} \parencite{Git} version
control software. Git when used in conjunction with \textit{GitHub}
\parencite{Github} enabled easy code backups to be hosted safely online.
Besides this, commit messages were aimed to be descriptive so that they serve
as a form of documentation of programmer's intentions.

The rest of the technologies used for this project form distinct groups and are
described in the following sections.

\subsubsection{Programming Language}

\textit{Ruby} programming language was chosen as the core technology for this
project due to author's familiarity with it and its related technologies. Ruby
is an object-oriented "dynamic, open source programming language with a focus
on simplicity and productivity. It has an elegant syntax that is natural to
read and easy to write" \parencite{Ruby}.

Ruby has many open-source libraries called \textit{gems} available, hosted and
managed locally by \textit{rubygems} software \parencite{Rubygems}. As these
gems have different versions and depencencies, they need to be managed on a
per-application basis - this process is made easy by \textit{bundler}
\parencite{Bundler}. More on these tools can be found in the Maintenance Manual
in Appendix \ref{sec:maintenance}.

\subsubsection{Cross-Platform Operation and Automation}

Managing different Ruby versions on a single computer can be cumbersome in case
it is needed for multiple Ruby applications. Furthermore, Ruby development for
Windows operating systems (OS) is several months behind development on Unix-
based systems \parencite{Ruby}, rendering the latest versions of Ruby unusable
directly on Windows, at the time of writing including the one this project is
using.

Fortunately, this can easily be avoided by using the following software:
\textit{VirtualBox} \parencite{Virtualbox} virtualisation software to host any
of the most popular OSs, \textit{Vagrant} \parencite{Vagrant} to automatically
manage the OSs and software installed on them, and \textit{RVM} \parencite{Rvm}
to manage Ruby versions on a single OS. Detailed instructions on using this
software stack with Ruby are in the Maintenance Manual in Appendix
\ref{sec:maintenance}. This method also means that the programmer can easily
move between computers as the setup costs are significantly reduced by
automation.


\subsubsection{Supporting Test-Driven Development}
\label{sec:design:software:tdd}

As was explained in Section \ref{sec:design:tdd}, Test-Driven Development (TDD)
is an important method for software development in this project. Therefore
supporting effective TDD is critical. \textit{RSpec} is a TDD testing tool for
Ruby \parencite{Rspec}. The tests are meant to describe the desired behaviour of
software in natural English.

An example RSpec test scenario is shown in Figure \ref{figure:RSpec}. This test
specifies behaviour of some ruby class 'Class' which should have a 'currency'
method that returns 'EURO'. If multiple tests are written specifying the
expected behaviour in different conditions, then RSpec tests becomes a form of
programmer-friendly documentation that is executable and protects the code from
introducing regression bugs.

\begin{figure}
  \begin{verbatim}
    describe Class do
      describe '#currency' do
        it 'is EURO' do
          instance = Class.new
          expect(instance.currency).to eq('EURO')
        end
      end
    end
  \end{verbatim}
  \caption{
    RSpec test example
    \label{figure:RSpec}
  }
\end{figure}

RSpec can be enhanced by other tools. \textit{Simplecov} \parencite{Simplecov}
is a code coverage tool that monitors test coverage of a codebase by checking
how many lines of code are executed when running the test suite. \textit{Guard}
\parencite{Guard} is a tool that monitors file changes and executes appropriate
events (i.e. running RSpec tests). This can make a developer's TDD workflow
streamlined leaving with only tests and code to write.

At the time of submission this project's test coverage according to Simplecov
was 99.72\% (1053/1056 lines of code covered). Of course, despite the RSpec
tests and Simplecov test coverage, they in no way guarantee correct and
effective code and could even lead to a false sense of security.
